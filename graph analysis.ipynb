{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10\n",
      "2.2\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "ox.config(use_cache=True,\n",
    "          log_file=True,\n",
    "          log_console=True,\n",
    "          log_filename='calculate-cities',\n",
    "          cache_folder=\"F:/ITC/proposal/test\")\n",
    "\n",
    "print(ox.__version__)\n",
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphml_folder ='folder'# place graphml files\n",
    "places_folder ='folder' # place shapefiles\n",
    "folder ='name' #the name of created folder for each country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creatr a datafram based on the attribute of shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city_file fuacode_si   fuaname_en iso3    name state_folder\n",
      "0     SE001_Stockholm      SE001     tockholm  SWE  Sweden   SWE_Sweden\n",
      "1    SE002_Gothenburg      SE002   Gothenburg  SWE  Sweden   SWE_Sweden\n",
      "2         SE003_Malmo      SE003        Malmo  SWE  Sweden   SWE_Sweden\n",
      "3     SE004_Jonkoping      SE004    Jonkoping  SWE  Sweden   SWE_Sweden\n",
      "4          SE005_Umea      SE005         Umea  SWE  Sweden   SWE_Sweden\n",
      "5       SE006_Uppsala      SE006      Uppsala  SWE  Sweden   SWE_Sweden\n",
      "6     SE007_Linkoping      SE007    Linkoping  SWE  Sweden   SWE_Sweden\n",
      "7        SE008_Orebro      SE008       Orebro  SWE  Sweden   SWE_Sweden\n",
      "8      SE501_Vasteras      SE501     Vasteras  SWE  Sweden   SWE_Sweden\n",
      "9    SE502_Norrkoping      SE502   Norrkoping  SWE  Sweden   SWE_Sweden\n",
      "10  SE503_Helsingborg      SE503  Helsingborg  SWE  Sweden   SWE_Sweden\n",
      "11        SE505_Boras      SE505        Boras  SWE  Sweden   SWE_Sweden\n"
     ]
    }
   ],
   "source": [
    "places = []\n",
    "for state_folder in folder:\n",
    "    for city_file in os.listdir('{}/{}'.format(graphml_folder, folder)):\n",
    "\n",
    "        data = {}\n",
    "        data['state_folder'] = folder\n",
    "        data['iso3'] = folder.split('_')[0]\n",
    "        data['name'] = folder.split('_')[1]\n",
    "        data['city_file'] = city_file\n",
    "        data['fuacode_si'] = city_file.split('_')[0]\n",
    "        data['fuaname_en'] = city_file.strip('_{}'.format(data['fuacode_si'])).replace('.graphml', '').replace('_', ' ')\n",
    "        \n",
    "        places.append(data)\n",
    "\n",
    "df = pd.DataFrame(places)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each state shapefile and get the geoid and aland for each city row\n",
    "gdf = gpd.GeoDataFrame()\n",
    "for x in df['name'].unique():\n",
    "    path = '{}/{}'.format(places_folder, x)\n",
    "    gdf = gdf.append(gpd.read_file(path)[['fuacode_si', 'area']])\n",
    "\n",
    "# merge aland values into dataframe, on geoid\n",
    "gdf = gdf.rename(columns=str.lower)\n",
    "df = pd.merge(df, gdf, how='left', on='fuacode_si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '{}/{}/{}'.format(graphml_folder, df['folder'],df['city_file'])\n",
    "\n",
    "df['graph'] = df['city_file'].apply(lambda x: \"{}.{}\".format(x, 'graphml'))\n",
    "filename=df['graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city_file fuacode_si   fuaname_en iso3    name state_folder  \\\n",
      "0     SE001_Stockholm      SE001     tockholm  SWE  Sweden   SWE_Sweden   \n",
      "1    SE002_Gothenburg      SE002   Gothenburg  SWE  Sweden   SWE_Sweden   \n",
      "2         SE003_Malmo      SE003        Malmo  SWE  Sweden   SWE_Sweden   \n",
      "3     SE004_Jonkoping      SE004    Jonkoping  SWE  Sweden   SWE_Sweden   \n",
      "4          SE005_Umea      SE005         Umea  SWE  Sweden   SWE_Sweden   \n",
      "5       SE006_Uppsala      SE006      Uppsala  SWE  Sweden   SWE_Sweden   \n",
      "6     SE007_Linkoping      SE007    Linkoping  SWE  Sweden   SWE_Sweden   \n",
      "7        SE008_Orebro      SE008       Orebro  SWE  Sweden   SWE_Sweden   \n",
      "8      SE501_Vasteras      SE501     Vasteras  SWE  Sweden   SWE_Sweden   \n",
      "9    SE502_Norrkoping      SE502   Norrkoping  SWE  Sweden   SWE_Sweden   \n",
      "10  SE503_Helsingborg      SE503  Helsingborg  SWE  Sweden   SWE_Sweden   \n",
      "11        SE505_Boras      SE505        Boras  SWE  Sweden   SWE_Sweden   \n",
      "\n",
      "            area                      graph  \n",
      "0   7.092070e+09    SE001_Stockholm.graphml  \n",
      "1   4.279870e+09   SE002_Gothenburg.graphml  \n",
      "2   1.862100e+09        SE003_Malmo.graphml  \n",
      "3   3.483040e+09    SE004_Jonkoping.graphml  \n",
      "4   9.784340e+09         SE005_Umea.graphml  \n",
      "5   6.871260e+09      SE006_Uppsala.graphml  \n",
      "6   4.238490e+09    SE007_Linkoping.graphml  \n",
      "7   3.694900e+09       SE008_Orebro.graphml  \n",
      "8   2.907110e+09     SE501_Vasteras.graphml  \n",
      "9   3.057970e+09   SE502_Norrkoping.graphml  \n",
      "10  1.139240e+09  SE503_Helsingborg.graphml  \n",
      "11  9.782170e+08        SE505_Boras.graphml  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_get_stats(row):\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        folder = '{}/{}/{}'.format(graphml_folder, row['folder'],row['city_file'])\n",
    "        filename=row['graph']\n",
    "        #filename=filename.append('{}.graphml')\n",
    "        G = ox.load_graphml(filename=filename, folder=folder)\n",
    "        \n",
    "        \n",
    "        stats = ox.basic_stats(G, area=row['area'])\n",
    "        edges = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
    "        \n",
    "        #d-number\n",
    "        count=edges['highway'].value_counts()\n",
    "        count_frame=count.to_frame()\n",
    "        count_main=[]\n",
    "        for i in count.index:\n",
    "            if type(i) is str:\n",
    "                x = count_frame.at[i, 'highway']\n",
    "                count_main.append(x)\n",
    "        N=count_main\n",
    "        T_N=sum(N)\n",
    "        D=[]\n",
    "        for i in np.arange(0,len(N),1):\n",
    "            E =N[i]*(N[i]-1)/(T_N*(T_N-1))\n",
    "            D.append(E)\n",
    "        summ_D= sum(D)\n",
    "        diversity_D_number=1-summ_D\n",
    "        stats.update( {'diversity_D_number' : diversity_D_number} )\n",
    "    \n",
    "    \n",
    "       #h-number\n",
    "        d=[]\n",
    "        for i in np.arange(0,len(N),1):\n",
    "            e =-(N[i]/T_N)*(np.log(N[i]/T_N))\n",
    "            d.append(e)\n",
    "        summ_H= sum(d)\n",
    "        diversity_H_number=summ_H\n",
    "        stats.update( {'diversity_H_number' : diversity_H_number} )\n",
    "    \n",
    "    \n",
    "    \n",
    "        #h-length\n",
    "        length=[]\n",
    "        for i in count.index:\n",
    "            if type(i) is str:\n",
    "                x = edges.loc[edges['highway'] ==i, 'length']\n",
    "                x =x .to_frame()\n",
    "                x  = x['length'].sum()\n",
    "                length.append(x)    \n",
    "        total=sum(length)\n",
    "        H=[]\n",
    "        for i in length:        \n",
    "            R=-(i/total)*(np.log(i/total))\n",
    "            H.append(R)\n",
    "        diversity_H_len= sum(H)\n",
    "        stats.update( {'diversity_H_len' : diversity_H_len} )\n",
    "    \n",
    "    \n",
    "    \n",
    "        #d-length\n",
    "        h=[]\n",
    "        for i in length:        \n",
    "            W =i*(i-1)/(total*(total-1))\n",
    "            h.append(W)\n",
    "        diversity_D_len=1- sum(h)\n",
    "        stats.update( {'diversity_D_len' : diversity_D_len} )\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "        #entropy\n",
    "        Gu = ox.add_edge_bearings(G)\n",
    "        bearings = pd.Series([data['bearing'] for u, v, k,  data in Gu.edges(keys=True, data=True)])\n",
    "        n = 36\n",
    "        n = n * 2\n",
    "        bins = np.arange(n + 1) * 360 / n\n",
    "        count, _ = np.histogram(bearings, bins=bins)\n",
    "        count = np.roll(count, 1)\n",
    "        count=count[::2] + count[1::2]\n",
    "        x=count.tolist()\n",
    "        total=sum(x)\n",
    "        H=[]\n",
    "        for i in np.arange(0,len(x),1):\n",
    "            E =-(x[i]/total)*(np.log(x[i]/total))\n",
    "            H.append(E)\n",
    "        E1= sum(H)\n",
    "        Emax=np.log(36)\n",
    "        Eg=1.386\n",
    "        E=1-((E1-Eg)/(Emax-Eg))*((E1-Eg)/(Emax-Eg))    \n",
    "        stats.update( {'entropy' : E} )\n",
    "        \n",
    "        \n",
    "        # unpack k-counts and k-proportion dicts into individiual keys:values\n",
    "        for k, count in stats['streets_per_node_counts'].items():\n",
    "            stats['int_{}_streets_count'.format(k)] = count\n",
    "        for k, proportion in stats['streets_per_node_proportion'].items():\n",
    "            stats['int_{}_streets_prop'.format(k)] = proportion\n",
    "            \n",
    "        # calculate/drop the extended stats that have values per node\n",
    "        extended_stats = ox.extended_stats(G)\n",
    "        se = pd.Series(extended_stats)\n",
    "        se = se.drop(['avg_neighbor_degree', 'avg_weighted_neighbor_degree', 'clustering_coefficient',\n",
    "                      'clustering_coefficient_weighted', 'degree_centrality', 'pagerank'])\n",
    "        extended_stats_clean = se.to_dict()\n",
    "        \n",
    "        for key in extended_stats_clean:\n",
    "            stats[key] = extended_stats_clean[key]\n",
    "        \n",
    "        stats['area_km'] = row['area'] / 1e6        \n",
    "        stats['city'] = row['fuaname_en']\n",
    "        stats['state'] = row['name']\n",
    "        stats['geoid'] = row['fuacode_si']\n",
    "        stats['area'] = row['area']\n",
    "        stats['time'] = time.time()-start_time\n",
    "        return pd.Series(stats)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('{}, {} failed: {}'.format(row['city'], row['state'], e))\n",
    "        return pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 58)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample = list(range(0, len(df), int(len(df)/100)))\n",
    "#stats = df.iloc[sample].apply(load_graph_get_stats, axis=1)\n",
    "stats_temp = df.apply(load_graph_get_stats, axis=1)\n",
    "stats_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_temp['time'].sum()\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff to drop\n",
    "cols_to_drop = ['area', 'time', 'streets_per_node_counts', 'streets_per_node_proportion', \n",
    "                'pagerank_max_node', 'pagerank_min_node', 'clean_intersection_count',\n",
    "                'clean_intersection_density_km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {}\n",
    "for col in stats.columns:\n",
    "    if 'int_' in col:\n",
    "        n = col.split('_')[1]\n",
    "        if n not in ['1', '3', '4']:\n",
    "            cols_to_drop.append(col)\n",
    "        else:\n",
    "            suffix = 'count' if 'count' in col else 'proportion'\n",
    "            cols_to_rename[col] = 'intersect_{}way_{}'.format(n, suffix)\n",
    "            \n",
    "stats = stats.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename these to friendlier names\n",
    "cols_to_rename['clustering_coefficient_avg'] = 'cluster_coeff_avg'\n",
    "cols_to_rename['clustering_coefficient_weighted_avg'] = 'cluster_coeff_weighted_avg'\n",
    "cols_to_rename['intersection_density_km'] = 'intersect_density_km'\n",
    "cols_to_rename['intersect_1way_count'] = 'dead_end_count'\n",
    "cols_to_rename['intersect_1way_proportion'] = 'dead_end_proportion'\n",
    "cols_to_rename['m'] = 'edge_count'\n",
    "cols_to_rename['n'] = 'node_count'\n",
    "stats = stats.rename(columns=cols_to_rename)\n",
    "stats = stats.rename(columns=cols_to_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop anything lacking a GEOID\n",
    "stats = stats.dropna(subset=['geoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make these integers\n",
    "cols_int = ['intersection_count', 'edge_length_total', 'edge_count', 'node_count', 'street_segments_count']\n",
    "stats[cols_int] = stats[cols_int].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make city, state, geoid at left of df\n",
    "cols = stats.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('city')))\n",
    "cols.insert(1, cols.pop(cols.index('state')))\n",
    "cols.insert(2, cols.pop(cols.index('geoid')))\n",
    "stats = stats.reindex(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 38)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'state', 'geoid', 'area_km', 'avg_neighbor_degree_avg',\n",
       "       'avg_weighted_neighbor_degree_avg', 'circuity_avg', 'cluster_coeff_avg',\n",
       "       'cluster_coeff_weighted_avg', 'degree_centrality_avg',\n",
       "       'diversity_D_len', 'diversity_D_number', 'diversity_H_len',\n",
       "       'diversity_H_number', 'edge_density_km', 'edge_length_avg',\n",
       "       'edge_length_total', 'entropy', 'dead_end_count', 'dead_end_proportion',\n",
       "       'intersect_3way_count', 'intersect_3way_proportion',\n",
       "       'intersect_4way_count', 'intersect_4way_proportion',\n",
       "       'intersection_count', 'intersect_density_km', 'k_avg', 'edge_count',\n",
       "       'node_count', 'node_density_km', 'pagerank_max', 'pagerank_min',\n",
       "       'self_loop_proportion', 'street_density_km', 'street_length_avg',\n",
       "       'street_length_total', 'street_segments_count', 'streets_per_node_avg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>geoid</th>\n",
       "      <th>area_km</th>\n",
       "      <th>avg_neighbor_degree_avg</th>\n",
       "      <th>avg_weighted_neighbor_degree_avg</th>\n",
       "      <th>circuity_avg</th>\n",
       "      <th>cluster_coeff_avg</th>\n",
       "      <th>cluster_coeff_weighted_avg</th>\n",
       "      <th>degree_centrality_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>node_count</th>\n",
       "      <th>node_density_km</th>\n",
       "      <th>pagerank_max</th>\n",
       "      <th>pagerank_min</th>\n",
       "      <th>self_loop_proportion</th>\n",
       "      <th>street_density_km</th>\n",
       "      <th>street_length_avg</th>\n",
       "      <th>street_length_total</th>\n",
       "      <th>street_segments_count</th>\n",
       "      <th>streets_per_node_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES001</td>\n",
       "      <td>1473.990</td>\n",
       "      <td>2.076407</td>\n",
       "      <td>0.054911</td>\n",
       "      <td>1.055438</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>...</td>\n",
       "      <td>65784</td>\n",
       "      <td>44.629882</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>6969.374859</td>\n",
       "      <td>104.216094</td>\n",
       "      <td>1.027279e+07</td>\n",
       "      <td>98572</td>\n",
       "      <td>2.998617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES002</td>\n",
       "      <td>714.982</td>\n",
       "      <td>2.075209</td>\n",
       "      <td>0.053353</td>\n",
       "      <td>1.065403</td>\n",
       "      <td>0.065556</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>...</td>\n",
       "      <td>44748</td>\n",
       "      <td>62.586191</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>9306.104464</td>\n",
       "      <td>96.655924</td>\n",
       "      <td>6.653697e+06</td>\n",
       "      <td>68839</td>\n",
       "      <td>3.082998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Valencia</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES003</td>\n",
       "      <td>416.358</td>\n",
       "      <td>2.114225</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>1.052252</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>...</td>\n",
       "      <td>23309</td>\n",
       "      <td>55.983072</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>8054.338202</td>\n",
       "      <td>95.288499</td>\n",
       "      <td>3.353488e+06</td>\n",
       "      <td>35193</td>\n",
       "      <td>3.030031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eville</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES004</td>\n",
       "      <td>673.770</td>\n",
       "      <td>2.215516</td>\n",
       "      <td>0.054370</td>\n",
       "      <td>1.054748</td>\n",
       "      <td>0.060268</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>...</td>\n",
       "      <td>22881</td>\n",
       "      <td>33.959660</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>4807.338656</td>\n",
       "      <td>95.319166</td>\n",
       "      <td>3.239041e+06</td>\n",
       "      <td>33981</td>\n",
       "      <td>2.971592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aragossa</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES005</td>\n",
       "      <td>1006.160</td>\n",
       "      <td>1.917614</td>\n",
       "      <td>0.048696</td>\n",
       "      <td>1.073749</td>\n",
       "      <td>0.097122</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>...</td>\n",
       "      <td>9904</td>\n",
       "      <td>9.843365</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>1785.297678</td>\n",
       "      <td>122.105575</td>\n",
       "      <td>1.796295e+06</td>\n",
       "      <td>14711</td>\n",
       "      <td>2.986066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        city  state  geoid   area_km  avg_neighbor_degree_avg  \\\n",
       "0     Madrid  Spain  ES001  1473.990                 2.076407   \n",
       "1  Barcelona  Spain  ES002   714.982                 2.075209   \n",
       "2   Valencia  Spain  ES003   416.358                 2.114225   \n",
       "3     eville  Spain  ES004   673.770                 2.215516   \n",
       "4   aragossa  Spain  ES005  1006.160                 1.917614   \n",
       "\n",
       "   avg_weighted_neighbor_degree_avg  circuity_avg  cluster_coeff_avg  \\\n",
       "0                          0.054911      1.055438           0.063325   \n",
       "1                          0.053353      1.065403           0.065556   \n",
       "2                          0.055468      1.052252           0.068038   \n",
       "3                          0.054370      1.054748           0.060268   \n",
       "4                          0.048696      1.073749           0.097122   \n",
       "\n",
       "   cluster_coeff_weighted_avg  degree_centrality_avg  ...  node_count  \\\n",
       "0                    0.000554               0.000061  ...       65784   \n",
       "1                    0.000538               0.000089  ...       44748   \n",
       "2                    0.000574               0.000173  ...       23309   \n",
       "3                    0.000431               0.000185  ...       22881   \n",
       "4                    0.000915               0.000374  ...        9904   \n",
       "\n",
       "   node_density_km  pagerank_max  pagerank_min  self_loop_proportion  \\\n",
       "0        44.629882      0.000080      0.000002              0.002737   \n",
       "1        62.586191      0.000130      0.000003              0.001754   \n",
       "2        55.983072      0.000203      0.000006              0.001129   \n",
       "3        33.959660      0.000251      0.000007              0.002227   \n",
       "4         9.843365      0.000512      0.000015              0.002941   \n",
       "\n",
       "   street_density_km  street_length_avg  street_length_total  \\\n",
       "0        6969.374859         104.216094         1.027279e+07   \n",
       "1        9306.104464          96.655924         6.653697e+06   \n",
       "2        8054.338202          95.288499         3.353488e+06   \n",
       "3        4807.338656          95.319166         3.239041e+06   \n",
       "4        1785.297678         122.105575         1.796295e+06   \n",
       "\n",
       "   street_segments_count  streets_per_node_avg  \n",
       "0                  98572              2.998617  \n",
       "1                  68839              3.082998  \n",
       "2                  35193              3.030031  \n",
       "3                  33981              2.971592  \n",
       "4                  14711              2.986066  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(stats_folder):\n",
    "    os.makedirs(stats_folder)\n",
    "output_path = '{}/{}/cities-stats.csv'.format(graphml_folder, stats_folder)\n",
    "\n",
    "stats.to_csv(output_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
